{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Predict Relation and Finish\n",
    "\n",
    "Our goal during this step is to predict the relation and compute the end-to-end accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils.connect import get_connection \n",
    "from scripts.utils.data import FB2M_NAME_TABLE\n",
    "\n",
    "connection = get_connection()\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c10992a84f14478b9f2b584080afe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_index</th>\n",
       "      <th>object</th>\n",
       "      <th>predicted_subject_names</th>\n",
       "      <th>question</th>\n",
       "      <th>question_tokens</th>\n",
       "      <th>relation</th>\n",
       "      <th>start_index</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_name</th>\n",
       "      <th>subject_name_tokens</th>\n",
       "      <th>candidate_mids</th>\n",
       "      <th>predicted_start_index</th>\n",
       "      <th>predicted_end_index</th>\n",
       "      <th>predicted_subject_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0bs56bp</td>\n",
       "      <td>[{'name': 'american thoroughbread', 'score': 1...</td>\n",
       "      <td>Name an American Thoroughbread racehorse</td>\n",
       "      <td>[name, an, american, thoroughbread, racehorse]</td>\n",
       "      <td>biology/organism_classification/organisms_of_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03k3r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[01z1jf2, 04q7gbh]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>9.0</td>\n",
       "      <td>01sjng</td>\n",
       "      <td>[{'name': 'vision racing driving simulator', '...</td>\n",
       "      <td>what kind of game is vision racing driving sim...</td>\n",
       "      <td>[what, kind, of, game, is, vision, racing, dri...</td>\n",
       "      <td>cvg/computer_videogame/cvg_genre</td>\n",
       "      <td>5.0</td>\n",
       "      <td>02qlppc</td>\n",
       "      <td>vision racing driving simulator</td>\n",
       "      <td>(vision, racing, driving, simulator)</td>\n",
       "      <td>[02qlppc]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>vision racing driving simulator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0dlmm88</td>\n",
       "      <td>[{'name': 'romance film', 'score': 28.02931404...</td>\n",
       "      <td>what tv program is romance film</td>\n",
       "      <td>[what, tv, program, is, romance, film]</td>\n",
       "      <td>tv/tv_genre/programs</td>\n",
       "      <td>4.0</td>\n",
       "      <td>02l7c8</td>\n",
       "      <td>romance film</td>\n",
       "      <td>(romance, film)</td>\n",
       "      <td>[02l7c8]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>romance film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>4.0</td>\n",
       "      <td>04rrx</td>\n",
       "      <td>[{'name': 'polaski', 'score': 32.1325416564941...</td>\n",
       "      <td>what state is  polaski located in</td>\n",
       "      <td>[what, state, is, polaski, located, in]</td>\n",
       "      <td>location/location/containedby</td>\n",
       "      <td>3.0</td>\n",
       "      <td>049_zj3</td>\n",
       "      <td>polaski</td>\n",
       "      <td>(polaski,)</td>\n",
       "      <td>[049_zj3]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>polaski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0qcr0</td>\n",
       "      <td>[{'name': 'fern emmett', 'score': 23.679399490...</td>\n",
       "      <td>what disease claimed the life of fern emmett</td>\n",
       "      <td>[what, disease, claimed, the, life, of, fern, ...</td>\n",
       "      <td>people/deceased_person/cause_of_death</td>\n",
       "      <td>6.0</td>\n",
       "      <td>02w9ycr</td>\n",
       "      <td>fern emmett</td>\n",
       "      <td>(fern, emmett)</td>\n",
       "      <td>[02w9ycr]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>fern emmett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       end_index   object                            predicted_subject_names  \\\n",
       "6219         NaN  0bs56bp  [{'name': 'american thoroughbread', 'score': 1...   \n",
       "3364         9.0   01sjng  [{'name': 'vision racing driving simulator', '...   \n",
       "9374         6.0  0dlmm88  [{'name': 'romance film', 'score': 28.02931404...   \n",
       "10142        4.0    04rrx  [{'name': 'polaski', 'score': 32.1325416564941...   \n",
       "97           8.0    0qcr0  [{'name': 'fern emmett', 'score': 23.679399490...   \n",
       "\n",
       "                                                question  \\\n",
       "6219           Name an American Thoroughbread racehorse    \n",
       "3364   what kind of game is vision racing driving sim...   \n",
       "9374                     what tv program is romance film   \n",
       "10142                  what state is  polaski located in   \n",
       "97          what disease claimed the life of fern emmett   \n",
       "\n",
       "                                         question_tokens  \\\n",
       "6219      [name, an, american, thoroughbread, racehorse]   \n",
       "3364   [what, kind, of, game, is, vision, racing, dri...   \n",
       "9374              [what, tv, program, is, romance, film]   \n",
       "10142            [what, state, is, polaski, located, in]   \n",
       "97     [what, disease, claimed, the, life, of, fern, ...   \n",
       "\n",
       "                                                relation  start_index  \\\n",
       "6219   biology/organism_classification/organisms_of_t...          NaN   \n",
       "3364                    cvg/computer_videogame/cvg_genre          5.0   \n",
       "9374                                tv/tv_genre/programs          4.0   \n",
       "10142                      location/location/containedby          3.0   \n",
       "97                 people/deceased_person/cause_of_death          6.0   \n",
       "\n",
       "       subject                     subject_name  \\\n",
       "6219     03k3r                              NaN   \n",
       "3364   02qlppc  vision racing driving simulator   \n",
       "9374    02l7c8                     romance film   \n",
       "10142  049_zj3                          polaski   \n",
       "97     02w9ycr                      fern emmett   \n",
       "\n",
       "                        subject_name_tokens      candidate_mids  \\\n",
       "6219                                    NaN  [01z1jf2, 04q7gbh]   \n",
       "3364   (vision, racing, driving, simulator)           [02qlppc]   \n",
       "9374                        (romance, film)            [02l7c8]   \n",
       "10142                            (polaski,)           [049_zj3]   \n",
       "97                           (fern, emmett)           [02w9ycr]   \n",
       "\n",
       "       predicted_start_index  predicted_end_index  \\\n",
       "6219                     2.0                  3.0   \n",
       "3364                     5.0                  9.0   \n",
       "9374                     4.0                  6.0   \n",
       "10142                    3.0                  4.0   \n",
       "97                       6.0                  8.0   \n",
       "\n",
       "                predicted_subject_name  \n",
       "6219                          american  \n",
       "3364   vision racing driving simulator  \n",
       "9374                      romance film  \n",
       "10142                          polaski  \n",
       "97                         fern emmett  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "df = pd.read_pickle('step_2_generate_candidates.pkl')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Facts\n",
    "\n",
    "Given the candidate mids, the we generate candidate facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def generate_facts(row):\n",
    "    cursor.execute(\"\"\"SELECT object_mid, relation, subject_mid\n",
    "                      FROM fb_two_kg\n",
    "                      WHERE subject_mid = ANY(%s)\"\"\", (row['candidate_mids'],))\n",
    "    rows = cursor.fetchall()\n",
    "    candidate_facts = defaultdict(lambda: defaultdict(set))\n",
    "    \n",
    "    for object_mid, relation, subject_mid in rows:\n",
    "        candidate_facts[relation][subject_mid].add(object_mid)\n",
    "        \n",
    "    return candidate_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46b3bf0e9734f2b9b3f461b8169a805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10845), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['candidate_facts'] = df.progress_apply(generate_facts, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upperbounds\n",
    "\n",
    "Check the accuracy of the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700b6ad2dde14e70894609fe4233f029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10845), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Object Canditate Accuracy: 0.9550023052097741\n",
      "Relation Canditate Accuracy: 0.9675426463808207\n",
      "Subject Canditate Accuracy: 0.9550023052097741\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "correct_object = 0\n",
    "correct_relation = 0\n",
    "correct_subject = 0\n",
    "for index, row in tqdm_notebook(df.iterrows(), total=df.shape[0]):\n",
    "    facts = row['candidate_facts']\n",
    "\n",
    "    if row['relation'] in facts:\n",
    "        correct_relation += 1\n",
    "        if row['subject'] in facts[row['relation']]:\n",
    "            correct_subject += 1\n",
    "            if row['object'] in facts[row['relation']][row['subject']]:\n",
    "                correct_object += 1    \n",
    "        \n",
    "\n",
    "print('Object Canditate Accuracy:', correct_object / df.shape[0])\n",
    "print('Relation Canditate Accuracy:', correct_relation / df.shape[0])\n",
    "print('Subject Canditate Accuracy:', correct_subject / df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Relation Model\n",
    "\n",
    "Load the baseline relation model.\n",
    "\n",
    "TODO: Replace with <e> model and spacy_tokenize\n",
    "\n",
    "TODO: Think about the probablistics <e> model stuff\n",
    "    \n",
    "TODO: Test a ranking model based on candidate aliases\n",
    "\n",
    "TODO: Check the best accuracy for relation classification with <e> if you guess the top relation\n",
    "    \n",
    "TODO: Clarify that <e> each has a bias toward some relation, we can compute that by looking at the distribution of FB2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'lib.nn.seq_to_label.SeqToLabel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.GRU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where was Obama born?\n",
      "Scores:\n",
      "0.8835899947877679\n",
      "0.11019587285726916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../lib/nn/seq_to_label.py:52: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  scores = F.log_softmax(output)\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "from lib.checkpoint import Checkpoint\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch\n",
    "\n",
    "BASELINE_RELATION_CLASSIFIER = '../../results/0756.12-22_15:25:19.relation_classifier/12m_22d_15h_37m_20s.pt'\n",
    "\n",
    "baseline_relation_classifer = Checkpoint(checkpoint_path=BASELINE_RELATION_CLASSIFIER, device=0)\n",
    "baseline_relation_classifer.model.train(mode=False)\n",
    "\n",
    "cuda = lambda v: v.cuda() if torch.cuda.is_available() else t\n",
    "to_variable = lambda e: cuda(Variable(torch.LongTensor(e).unsqueeze(1).contiguous()))\n",
    "\n",
    "@lru_cache(maxsize=16384)\n",
    "def model(question):\n",
    "    encoded = baseline_relation_classifer.input_text_encoder.encode(question)\n",
    "    encoded = to_variable(encoded)\n",
    "    encoded_length = torch.LongTensor([encoded.size()[0]])\n",
    "    output_batch = baseline_relation_classifer.model(encoded, encoded_length)[0]\n",
    "    output_batch = output_batch.squeeze(0)\n",
    "    return output_batch.data\n",
    "\n",
    "@lru_cache(maxsize=16384)\n",
    "def get_baseline_relation_score(question, relation):\n",
    "    relation = 'www.freebase.com' + relation\n",
    "    question = question.lower()\n",
    "    output_batch = model(question)\n",
    "    relation_index = baseline_relation_classifer.output_text_encoder.encode(relation)[0]\n",
    "    return math.exp(output_batch[relation_index])\n",
    "    \n",
    "## Test ##\n",
    "question = 'Where was Obama born?'\n",
    "print('Question:', question)\n",
    "print('Scores:')\n",
    "print(get_baseline_relation_score(question, '/people/person/place_of_birth'))\n",
    "print(get_baseline_relation_score(question, '/location/location/people_born_here'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Model Yu et Al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: where was #head_entity# born ?\n",
      "Scores:\n",
      "0.7156175971031189\n",
      "0.6886991858482361\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "RELATION_CLASSIFIER = '../../logs/2785.01-01_17:32:06.yu_relation_model/01m_01d_17h_54m_53s.pt'\n",
    "\n",
    "import pprint\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "from lib.checkpoint import Checkpoint\n",
    "\n",
    "pretty_printer = pprint.PrettyPrinter(indent=2)\n",
    "tokenizer = TreebankWordTokenizer() # Same tokenizer used during training\n",
    "\n",
    "relation_classifier = Checkpoint(checkpoint_path=RELATION_CLASSIFIER, device=0)\n",
    "relation_classifier.model.relation_word_rnn.flatten_parameters()\n",
    "relation_classifier.model.relation_rnn.flatten_parameters()\n",
    "relation_classifier.model.text_rnn.flatten_parameters()\n",
    "relation_classifier.model.train(mode=False)\n",
    "\n",
    "cuda = lambda v: v.cuda() if torch.cuda.is_available() else t\n",
    "to_variable = lambda e: cuda(Variable(torch.LongTensor(e).unsqueeze(1).contiguous()))\n",
    "    \n",
    "def get_relation_score(question, relation):\n",
    "    question = question.lower()\n",
    "    question_encoded = relation_classifier.text_encoder.encode(question)\n",
    "    relation_encoded = relation_classifier.relation_encoder.encode(relation)\n",
    "    relation_word_encoded = relation_classifier.relation_word_encoder.encode(relation)\n",
    "\n",
    "    question_encoded = to_variable(question_encoded)\n",
    "    relation_encoded = to_variable(relation_encoded)\n",
    "    relation_word_encoded = to_variable(relation_word_encoded)\n",
    "\n",
    "    return relation_classifier.model(question_encoded, relation_encoded, relation_word_encoded).data[0]\n",
    "\n",
    "# To test this cell\n",
    "question = 'where was #head_entity# born ?'\n",
    "print('Question:', question)\n",
    "print('Scores:')\n",
    "print(get_relation_score(question, '/people/person/place_of_birth'))\n",
    "print(get_relation_score(question, '/location/location/people_born_here'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final End-To-End Metric\n",
    "\n",
    "Given candidate facts compute the end-to-end metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f13eaa32fbc4635b49a43ba93504723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10845), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject & Relation Accuracy (SOTA 78.7%): 0.668326 [7248 of 10845]\n",
      "Object Accuracy: 0.000000 [0 of 10845]\n",
      "Relation Accuracy (SOTA 89%): 0.872937 [9467 of 10845]\n",
      "Subject Accuracy (SOTA 79%): 0.724297 [7855 of 10845]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from numpy import nan\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "subject_and_relation_correct = 0\n",
    "object_correct = 0\n",
    "relation_correct = 0\n",
    "subject_mid_correct = 0\n",
    "for index, row in tqdm_notebook(df.iterrows(), total=df.shape[0]):\n",
    "    if len(row['candidate_facts']) != 0:\n",
    "        # TODO: Multiple relations are correct given any question; therefore, its important for us to compute\n",
    "        # the probabilty that one of the correct relations. \n",
    "        # Model approximates the P(r | q)\n",
    "        # Should we approximate P(r) instead\n",
    "        # We should not approximate P(r | q, e) because P(r | e) is exactly known\n",
    "        # QUESTION: Is it important to consider multiple relations, incase for a particular E, one relation makes\n",
    "        # much more sense? -- Multiple relations -> P(r | q) * P(r | e) \n",
    "        # = P(r and q) / P(q) * P(r and e) / P(e)\n",
    "        # = P(r and q and e) / P(q and e)\n",
    "        # = P(r | q, e) \n",
    "        # Multiple them together?\n",
    "        # TODO: Compute the upperbound for relation accuracy given half the question templates overlap\n",
    "#         max_relation = max([r for r in row['candidate_facts']],\n",
    "#                            key=lambda r: get_baseline_relation_score(row['question'], '/' + r))\n",
    "        \n",
    "        # We use the `Better than random guessing` from notebook \n",
    "        # `HYPOTHESIS - Question Refers to Multiple Subjects`.\n",
    "        # subject_mid, object_mids = random.sample(row['candidate_facts'][max_relation].items(), 1)[0]\n",
    "#         subject_mid, object_mids = sorted(row['candidate_facts'][max_relation].items(),\n",
    "#                                           key=lambda i: len(i[1]), reverse=True)[0]\n",
    "        \n",
    "        max_score = 0\n",
    "        max_subject_mid = None\n",
    "        max_relation = None\n",
    "        max_object_mids = None\n",
    "        \n",
    "        for r in row['candidate_facts']:\n",
    "            probability_relation_given_question = get_baseline_relation_score(row['question'], '/' + r)\n",
    "            for subject_mid in row['candidate_facts'][r]:\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT count(*)\n",
    "                    FROM fb_two_kg\n",
    "                    WHERE subject_mid = %s\n",
    "                \"\"\", (subject_mid,))\n",
    "                n_facts = cursor.fetchall()[0][0]\n",
    "                probability_relation_given_entity = len(row['candidate_facts'][r][subject_mid]) / n_facts\n",
    "                score = probability_relation_given_entity * probability_relation_given_question\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    max_object_mids = row['candidate_facts'][r][subject_mid]\n",
    "                    max_subject_mid = subject_mid\n",
    "                    max_relation = r\n",
    "\n",
    "        if max_relation == row['relation'] and subject_mid == row['subject']:\n",
    "            subject_and_relation_correct += 1\n",
    "        if row['object'] in object_mids:\n",
    "            object_correct += 1\n",
    "        if max_relation == row['relation']:\n",
    "            relation_correct += 1\n",
    "        if subject_mid == row['subject']:\n",
    "            subject_mid_correct += 1\n",
    "\n",
    "# TODO: Look into why the relation accuracy is worse than before\n",
    "# Baseline Relation Model\n",
    "# Subject & Relation Accuracy: 0.776763 [8424 of 10845]\n",
    "# Object Accuracy: 0.833195 [9036 of 10845]\n",
    "# Relation Accuracy: 0.873490 [9473 of 10845]\n",
    "# Subject MID Accuracy: 0.834025 [9045 of 10845]\n",
    "            \n",
    "print('Subject & Relation Accuracy (SOTA 78.7%%): %f [%d of %d]' %\n",
    "          (subject_and_relation_correct / df.shape[0], subject_and_relation_correct, df.shape[0]))\n",
    "print('Object Accuracy: %f [%d of %d]' %\n",
    "          (object_correct / df.shape[0], object_correct, df.shape[0]))\n",
    "print('Relation Accuracy (SOTA 89%%): %f [%d of %d]' %\n",
    "          (relation_correct / df.shape[0], relation_correct, df.shape[0]))\n",
    "print('Subject Accuracy (SOTA 79%%): %f [%d of %d]' %\n",
    "          (subject_mid_correct / df.shape[0], subject_mid_correct, df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
