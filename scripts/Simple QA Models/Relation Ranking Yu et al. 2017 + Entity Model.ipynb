{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Ranking Yu et al. 2017 Model\n",
    "\n",
    "Our goal here to to reimplement Yu et al. 2017 93% relation model. \n",
    "\n",
    "First things first, set up the initial configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.4 (default, Dec 19 2017, 17:29:45) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Python Version:', sys.version)\n",
    "import pandas as pd\n",
    "import logging\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from lib.utils import setup_training\n",
    "\n",
    "# Create root logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 80)\n",
    "\n",
    "random_seed = 123\n",
    "device = 0\n",
    "is_cuda, _ = setup_training(device, random_seed) \n",
    "# Async minibatch allocation for speed\n",
    "# Reference: http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/\n",
    "# TODO: look into cuda_async device=device\n",
    "cuda_async = lambda t: t.cuda(device=device, async=True) if is_cuda else t  # Use with tensors\n",
    "cuda = lambda t: t.cuda(device=device) if is_cuda else t  # Use with nn.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Load our dataset. Log a couple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from lib.datasets.dataset import Dataset\n",
    "\n",
    "def yu_dataset(directory='../../data/yu/',\n",
    "               train=False,\n",
    "               dev=False,\n",
    "               test=False,\n",
    "               train_filename='train.replace_ne.withpool',\n",
    "               dev_filename='valid.replace_ne.withpool',\n",
    "               test_filename='test.replace_ne.withpool',\n",
    "               vocab_filename='relation.2M.list'):\n",
    "    \"\"\"\n",
    "    Example line example: 40\t61 40 117\twhich genre of album is #head_entity# ?\n",
    "    Vocab example: /film/film/genre\n",
    "    \n",
    "    Sample Data:\n",
    "        Question: 'which genre of album is #head_entity# ?'\n",
    "        True Relation: '/music/album/genre'\n",
    "        False Relation Pool: ['/music/album/release_type', '/music/album/genre', '/music/album/artist']\n",
    "    \"\"\"\n",
    "    vocab_path = os.path.join(directory, vocab_filename)\n",
    "    vocab = [l.strip() for l in open(vocab_path, 'r')]\n",
    "    \n",
    "    ret = []\n",
    "    datasets = [(train, train_filename), (dev, dev_filename), (test, test_filename)]\n",
    "    for is_requested, filename in datasets:\n",
    "        if not is_requested:\n",
    "            continue\n",
    "            \n",
    "        file_path = os.path.join(directory, filename)\n",
    "        data = pd.read_table(file_path, header=None, names=['True Relation', 'Relation Pool', 'Question'])\n",
    "        rows = []\n",
    "        for i, row in tqdm_notebook(data.iterrows(), total=data.shape[0]):\n",
    "            if row['Relation Pool'].strip() == 'noNegativeAnswer':\n",
    "                continue\n",
    "            relation_pool = [vocab[int(i) - 1].strip('/') for i in row['Relation Pool'].split()]\n",
    "            true_relation = vocab[int(row['True Relation']) - 1].strip('/')\n",
    "            question = row['Question'].strip()\n",
    "            # Development and test set may or may not have the True relation based on our predicted pool\n",
    "            if filename == train_filename:\n",
    "                assert true_relation not in relation_pool\n",
    "                \n",
    "            for relation in relation_pool:\n",
    "                if filename == train_filename:\n",
    "                    rows.append({'Question': question,\n",
    "                                 'True Relation': true_relation,\n",
    "                                 'False Relation': relation,\n",
    "                                 'Example ID': i})\n",
    "                else:\n",
    "                    rows.append({'Question': question,\n",
    "                                 'True Relation': true_relation,\n",
    "                                 'Relation': relation,\n",
    "                                 'Example ID': i})\n",
    "        ret.append(Dataset(rows))\n",
    "\n",
    "    if len(ret) == 1:\n",
    "        return ret[0]\n",
    "    else:\n",
    "        return tuple(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from lib.datasets.dataset import Dataset\n",
    "\n",
    "def relation_ranking_dataset(directory='../../data/relation_ranking/',\n",
    "               train=False,\n",
    "               dev=False,\n",
    "               test=False,\n",
    "               train_filename='train.txt',\n",
    "               dev_filename='dev.txt',\n",
    "               test_filename=''):\n",
    "    \"\"\"\n",
    "    Example line example: \n",
    "        film/film/country\tfilm/film/country film/film/genre film/film/language\twhat country is <e> from ?\n",
    "    Vocab example: \n",
    "        /film/film/genre\n",
    "    \n",
    "    Sample Data:\n",
    "        Question: 'which genre of album is #head_entity# ?'\n",
    "        True Relation: '/music/album/genre'\n",
    "        False Relation Pool: ['/music/album/release_type', '/music/album/genre', '/music/album/artist']\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    datasets = [(train, train_filename), (dev, dev_filename), (test, test_filename)]\n",
    "    for is_requested, filename in datasets:\n",
    "        if not is_requested:\n",
    "            continue\n",
    "            \n",
    "        file_path = os.path.join(directory, filename)\n",
    "        file = open(file_path)\n",
    "        lines = [tuple(l.split('\\t')) for l in file]\n",
    "        rows = []\n",
    "        for i, (true_relation, relation_pool, question, entity) in enumerate(lines):\n",
    "            relation_pool = set(relation_pool.split())\n",
    "            true_relation = true_relation\n",
    "            question = question.strip()\n",
    "            entity = entity.strip()\n",
    "            \n",
    "            # Development and test set may or may not have the True relation based on our predicted pool\n",
    "            if filename == train_filename:\n",
    "                relation_pool.remove(true_relation)\n",
    "                relation_pool = list(relation_pool)\n",
    "                \n",
    "            for relation in relation_pool:\n",
    "                if filename == train_filename:\n",
    "                    rows.append({'Question': question,\n",
    "                                 'Entity': entity,\n",
    "                                 'True Relation': true_relation,\n",
    "                                 'False Relation': relation,\n",
    "                                 'Example ID': i})\n",
    "                else:\n",
    "                    rows.append({'Question': question,\n",
    "                                 'Entity': entity,\n",
    "                                 'True Relation': true_relation,\n",
    "                                 'Relation': relation,\n",
    "                                 'Example ID': i})\n",
    "        ret.append(Dataset(rows))\n",
    "\n",
    "    if len(ret) == 1:\n",
    "        return ret[0]\n",
    "    else:\n",
    "        return tuple(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Training Data: 1312665\n",
      "Train Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Example ID</th>\n",
       "      <th>False Relation</th>\n",
       "      <th>Question</th>\n",
       "      <th>True Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>user/tsegaran/mathematics/mathematical_concept/discoverer</td>\n",
       "      <td>what is the book &lt;e&gt; about</td>\n",
       "      <td>book/written_work/subjects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>book/book/genre</td>\n",
       "      <td>what is the book &lt;e&gt; about</td>\n",
       "      <td>book/written_work/subjects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>common/topic/notable_types</td>\n",
       "      <td>what is the book &lt;e&gt; about</td>\n",
       "      <td>book/written_work/subjects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>music/composer/compositions</td>\n",
       "      <td>what is the book &lt;e&gt; about</td>\n",
       "      <td>book/written_work/subjects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>symbols/namesake/named_after</td>\n",
       "      <td>what is the book &lt;e&gt; about</td>\n",
       "      <td>book/written_work/subjects</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entity  Example ID                                             False Relation                    Question               True Relation\n",
       "0      e           0  user/tsegaran/mathematics/mathematical_concept/discoverer  what is the book <e> about  book/written_work/subjects\n",
       "1      e           0                                            book/book/genre  what is the book <e> about  book/written_work/subjects\n",
       "2      e           0                                 common/topic/notable_types  what is the book <e> about  book/written_work/subjects\n",
       "3      e           0                                music/composer/compositions  what is the book <e> about  book/written_work/subjects\n",
       "4      e           0                               symbols/namesake/named_after  what is the book <e> about  book/written_work/subjects"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num Development Data: 196297\n",
      "Development Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Example ID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Relation</th>\n",
       "      <th>True Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american</td>\n",
       "      <td>0</td>\n",
       "      <td>name an &lt;e&gt; thoroughbread racehorse</td>\n",
       "      <td>common/topic/notable_types</td>\n",
       "      <td>biology/organism_classification/organisms_of_this_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>0</td>\n",
       "      <td>name an &lt;e&gt; thoroughbread racehorse</td>\n",
       "      <td>dining/cuisine/ingredients</td>\n",
       "      <td>biology/organism_classification/organisms_of_this_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american</td>\n",
       "      <td>0</td>\n",
       "      <td>name an &lt;e&gt; thoroughbread racehorse</td>\n",
       "      <td>dining/cuisine/restaurant</td>\n",
       "      <td>biology/organism_classification/organisms_of_this_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>american</td>\n",
       "      <td>0</td>\n",
       "      <td>name an &lt;e&gt; thoroughbread racehorse</td>\n",
       "      <td>symbols/namesake/named_after</td>\n",
       "      <td>biology/organism_classification/organisms_of_this_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american</td>\n",
       "      <td>0</td>\n",
       "      <td>name an &lt;e&gt; thoroughbread racehorse</td>\n",
       "      <td>people/ethnicity/languages_spoken</td>\n",
       "      <td>biology/organism_classification/organisms_of_this_type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Entity  Example ID                             Question                           Relation                                           True Relation\n",
       "0  american           0  name an <e> thoroughbread racehorse         common/topic/notable_types  biology/organism_classification/organisms_of_this_type\n",
       "1  american           0  name an <e> thoroughbread racehorse         dining/cuisine/ingredients  biology/organism_classification/organisms_of_this_type\n",
       "2  american           0  name an <e> thoroughbread racehorse          dining/cuisine/restaurant  biology/organism_classification/organisms_of_this_type\n",
       "3  american           0  name an <e> thoroughbread racehorse       symbols/namesake/named_after  biology/organism_classification/organisms_of_this_type\n",
       "4  american           0  name an <e> thoroughbread racehorse  people/ethnicity/languages_spoken  biology/organism_classification/organisms_of_this_type"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "train_dataset, dev_dataset = relation_ranking_dataset(train=True, dev=True)\n",
    "\n",
    "print('Num Training Data: %d' % len(train_dataset))\n",
    "print('Train Sample:')\n",
    "display(pd.DataFrame(train_dataset[:5]))\n",
    "print('\\nNum Development Data: %d' % len(dev_dataset))\n",
    "print('Development Sample:')\n",
    "display(pd.DataFrame(dev_dataset[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.checkpoint import Checkpoint\n",
    "\n",
    "# Load a checkpoint\n",
    "checkpoint_path = None # '../../results/0000.01-22_09:00:26.yu_relation_model/01m_22d_09h_35m_44s.pt'\n",
    "if checkpoint_path is not None:\n",
    "    checkpoint = Checkpoint(checkpoint_path, device=0)\n",
    "else:\n",
    "    checkpoint = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Text\n",
    "\n",
    "Here we encode our data into a numerical format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoder vocab size: 6428\n",
      "Entity encoder vocab size: 48079\n",
      "Relation word encoder vocab size: 3390\n",
      "Relation encoder vocab size: 5268\n",
      "Train Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Example ID</th>\n",
       "      <th>False Relation</th>\n",
       "      <th>False Relation Word</th>\n",
       "      <th>Question</th>\n",
       "      <th>True Relation</th>\n",
       "      <th>True Relation Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3456]</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 188, 2957, 265, 575]</td>\n",
       "      <td>[8, 140, 1904, 67, 425, 421]</td>\n",
       "      <td>[3841, 4433, 773, 3755, 5232, 4318]</td>\n",
       "      <td>[1635, 3219, 1784]</td>\n",
       "      <td>[1076, 1453, 2092, 1175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3456]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1635, 1635, 3132]</td>\n",
       "      <td>[1076, 1076, 2024]</td>\n",
       "      <td>[3841, 4433, 773, 3755, 5232, 4318]</td>\n",
       "      <td>[1635, 3219, 1784]</td>\n",
       "      <td>[1076, 1453, 2092, 1175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3456]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1672, 544, 1133]</td>\n",
       "      <td>[1100, 401, 1481, 1130]</td>\n",
       "      <td>[3841, 4433, 773, 3755, 5232, 4318]</td>\n",
       "      <td>[1635, 3219, 1784]</td>\n",
       "      <td>[1076, 1453, 2092, 1175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3456]</td>\n",
       "      <td>0</td>\n",
       "      <td>[713, 1384, 4667]</td>\n",
       "      <td>[492, 916, 3009]</td>\n",
       "      <td>[3841, 4433, 773, 3755, 5232, 4318]</td>\n",
       "      <td>[1635, 3219, 1784]</td>\n",
       "      <td>[1076, 1453, 2092, 1175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3456]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1218, 2134, 4900]</td>\n",
       "      <td>[816, 1397, 1649, 1988]</td>\n",
       "      <td>[3841, 4433, 773, 3755, 5232, 4318]</td>\n",
       "      <td>[1635, 3219, 1784]</td>\n",
       "      <td>[1076, 1453, 2092, 1175]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entity  Example ID             False Relation           False Relation Word                             Question       True Relation        True Relation Word\n",
       "0  [3456]           0  [10, 188, 2957, 265, 575]  [8, 140, 1904, 67, 425, 421]  [3841, 4433, 773, 3755, 5232, 4318]  [1635, 3219, 1784]  [1076, 1453, 2092, 1175]\n",
       "1  [3456]           0         [1635, 1635, 3132]            [1076, 1076, 2024]  [3841, 4433, 773, 3755, 5232, 4318]  [1635, 3219, 1784]  [1076, 1453, 2092, 1175]\n",
       "2  [3456]           0          [1672, 544, 1133]       [1100, 401, 1481, 1130]  [3841, 4433, 773, 3755, 5232, 4318]  [1635, 3219, 1784]  [1076, 1453, 2092, 1175]\n",
       "3  [3456]           0          [713, 1384, 4667]              [492, 916, 3009]  [3841, 4433, 773, 3755, 5232, 4318]  [1635, 3219, 1784]  [1076, 1453, 2092, 1175]\n",
       "4  [3456]           0         [1218, 2134, 4900]       [816, 1397, 1649, 1988]  [3841, 4433, 773, 3755, 5232, 4318]  [1635, 3219, 1784]  [1076, 1453, 2092, 1175]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Example ID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Relation Word</th>\n",
       "      <th>True Relation</th>\n",
       "      <th>True Relation Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[22900]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1387, 3324, 5232, 5009, 4110]</td>\n",
       "      <td>[1672, 544, 1133]</td>\n",
       "      <td>[1100, 401, 1481, 1130]</td>\n",
       "      <td>[5008, 1263, 176]</td>\n",
       "      <td>[3218, 2272, 1340, 2224, 730, 2654, 2993]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[22900]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1387, 3324, 5232, 5009, 4110]</td>\n",
       "      <td>[1349, 4886, 4768]</td>\n",
       "      <td>[900, 3138, 3058]</td>\n",
       "      <td>[5008, 1263, 176]</td>\n",
       "      <td>[3218, 2272, 1340, 2224, 730, 2654, 2993]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[22900]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1387, 3324, 5232, 5009, 4110]</td>\n",
       "      <td>[1349, 4886, 160]</td>\n",
       "      <td>[900, 3138, 120]</td>\n",
       "      <td>[5008, 1263, 176]</td>\n",
       "      <td>[3218, 2272, 1340, 2224, 730, 2654, 2993]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22900]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1387, 3324, 5232, 5009, 4110]</td>\n",
       "      <td>[1218, 2134, 4900]</td>\n",
       "      <td>[816, 1397, 1649, 1988]</td>\n",
       "      <td>[5008, 1263, 176]</td>\n",
       "      <td>[3218, 2272, 1340, 2224, 730, 2654, 2993]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[22900]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1387, 3324, 5232, 5009, 4110]</td>\n",
       "      <td>[725, 4958, 4239]</td>\n",
       "      <td>[495, 3179, 2623, 801]</td>\n",
       "      <td>[5008, 1263, 176]</td>\n",
       "      <td>[3218, 2272, 1340, 2224, 730, 2654, 2993]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Entity  Example ID                        Question            Relation            Relation Word      True Relation                         True Relation Word\n",
       "0  [22900]           0  [1387, 3324, 5232, 5009, 4110]   [1672, 544, 1133]  [1100, 401, 1481, 1130]  [5008, 1263, 176]  [3218, 2272, 1340, 2224, 730, 2654, 2993]\n",
       "1  [22900]           0  [1387, 3324, 5232, 5009, 4110]  [1349, 4886, 4768]        [900, 3138, 3058]  [5008, 1263, 176]  [3218, 2272, 1340, 2224, 730, 2654, 2993]\n",
       "2  [22900]           0  [1387, 3324, 5232, 5009, 4110]   [1349, 4886, 160]         [900, 3138, 120]  [5008, 1263, 176]  [3218, 2272, 1340, 2224, 730, 2654, 2993]\n",
       "3  [22900]           0  [1387, 3324, 5232, 5009, 4110]  [1218, 2134, 4900]  [816, 1397, 1649, 1988]  [5008, 1263, 176]  [3218, 2272, 1340, 2224, 730, 2654, 2993]\n",
       "4  [22900]           0  [1387, 3324, 5232, 5009, 4110]   [725, 4958, 4239]   [495, 3179, 2623, 801]  [5008, 1263, 176]  [3218, 2272, 1340, 2224, 730, 2654, 2993]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import re\n",
    "\n",
    "from lib.text_encoders import StaticTokenizerEncoder\n",
    "from lib.text_encoders import DelimiterEncoder\n",
    "from lib.text_encoders import WordEncoder\n",
    "\n",
    "# We add development dataset to text_encoder for embeddings\n",
    "# We make sure not to use the the development dataset to provide us with any vocab optimizations or learning\n",
    "if checkpoint is None:\n",
    "    text_encoder = WordEncoder(train_dataset['Question'] + dev_dataset['Question'], lower=True, append_eos=False)\n",
    "    print('Text encoder vocab size: %d' % text_encoder.vocab_size)\n",
    "    \n",
    "    entity_encoder = WordEncoder(train_dataset['Entity'] + dev_dataset['Entity'], lower=True, append_eos=False)\n",
    "    print('Entity encoder vocab size: %d' % entity_encoder.vocab_size)\n",
    "\n",
    "    relations = set(train_dataset['True Relation'] + train_dataset['False Relation'])\n",
    "    relation_word_encoder = StaticTokenizerEncoder(relations, tokenize=lambda s: re.split('/|_', s))\n",
    "    print('Relation word encoder vocab size: %d' % relation_word_encoder.vocab_size)\n",
    "\n",
    "    relation_encoder = DelimiterEncoder('/', relations)\n",
    "    print('Relation encoder vocab size: %d' % relation_encoder.vocab_size)\n",
    "else:\n",
    "    relation_word_encoder = checkpoint.relation_word_encoder\n",
    "    relation_encoder = checkpoint.relation_encoder\n",
    "    text_encoder = checkpoint.text_encoder\n",
    "    entity_encoder = checkpoint.entity_encoder\n",
    "\n",
    "for dataset in [train_dataset, dev_dataset]:\n",
    "    for row in dataset:\n",
    "        row['Question'] = text_encoder.encode(row['Question'])\n",
    "        row['Entity'] = entity_encoder.encode(row['Entity'])\n",
    "        row['True Relation Word'] = relation_word_encoder.encode(row['True Relation'])\n",
    "        row['True Relation'] = relation_encoder.encode(row['True Relation'])\n",
    "        \n",
    "        if 'False Relation' in row:\n",
    "            row['False Relation Word'] = relation_word_encoder.encode(row['False Relation'])\n",
    "            row['False Relation'] = relation_encoder.encode(row['False Relation'])\n",
    "\n",
    "        if 'Relation' in row:\n",
    "            row['Relation Word'] = relation_word_encoder.encode(row['Relation'])\n",
    "            row['Relation'] = relation_encoder.encode(row['Relation'])\n",
    "            \n",
    "\n",
    "print('Train Sample:')\n",
    "display(pd.DataFrame(train_dataset[:5]))\n",
    "print('Development Sample:')\n",
    "display(pd.DataFrame(dev_dataset[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Iterators\n",
    "\n",
    "Define functions to create iterators over the development and the train dataset for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lib.utils import pad_batch\n",
    "from lib.samplers import BucketBatchSampler\n",
    "from lib.samplers import SortedSampler\n",
    "\n",
    "\n",
    "# Defines how to combine a batch of rows into a tensor\n",
    "def collate_fn(batch, train=True):\n",
    "    \"\"\" list of tensors to a batch variable \"\"\"\n",
    "    question_batch, _ = pad_batch([row['Question'] for row in batch])\n",
    "    entity_batch, _ = pad_batch([row['Entity'] for row in batch])\n",
    "\n",
    "    # PyTorch RNN requires batches to be transposed for speed and integration with CUDA\n",
    "    to_variable = (lambda b: Variable(torch.stack(b).t_().contiguous(), volatile=not train))\n",
    "\n",
    "    if train:\n",
    "        true_relation_word_batch, _ = pad_batch([row['True Relation Word'] for row in batch])\n",
    "        true_relation_batch, _ = pad_batch([row['True Relation'] for row in batch])\n",
    "        false_relation_word_batch, _ = pad_batch([row['False Relation Word'] for row in batch])\n",
    "        false_relation_batch, _ = pad_batch([row['False Relation'] for row in batch])\n",
    "        return (to_variable(question_batch), to_variable(entity_batch), to_variable(true_relation_batch),\n",
    "                to_variable(true_relation_word_batch), to_variable(false_relation_batch),\n",
    "                to_variable(false_relation_word_batch))\n",
    "    else:\n",
    "        relation_word_batch, _ = pad_batch([row['Relation Word'] for row in batch])\n",
    "        relation_batch, _ = pad_batch([row['Relation'] for row in batch])\n",
    "        return (to_variable(question_batch), to_variable(entity_batch), to_variable(relation_batch),\n",
    "                to_variable(relation_word_batch), batch)\n",
    "\n",
    "\n",
    "def make_train_iterator(train_batch_size):\n",
    "    # Use bucket sampling to group similar sized text but with noise + random\n",
    "    sort_key = lambda r: r['Entity'].size()[0]\n",
    "    batch_sampler = BucketBatchSampler(train_dataset, sort_key, train_batch_size)\n",
    "    return DataLoader(\n",
    "        train_dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=is_cuda,\n",
    "        num_workers=0)\n",
    "\n",
    "\n",
    "def make_dev_iterator(dev_batch_size):\n",
    "    # Group together all examples for metrics and sort questions of similar sizes for speed\n",
    "    sort_key = lambda r: (r['Entity'].size()[0], r['Example ID'])\n",
    "    return DataLoader(\n",
    "        dev_dataset,\n",
    "        batch_size=dev_batch_size,\n",
    "        sampler=SortedSampler(dev_dataset, sort_key, sort_noise=0.0),\n",
    "        collate_fn=partial(collate_fn, train=False),\n",
    "        pin_memory=is_cuda,\n",
    "        num_workers=0)\n",
    "\n",
    "\n",
    "# Just to make sure everything runs\n",
    "train_iterator_test = make_train_iterator(512)\n",
    "dev_iterator_test = make_dev_iterator(512)\n",
    "# Clear memory\n",
    "train_iterator_test = None\n",
    "dev_iterator_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "\n",
    "Instantiate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import MarginRankingLoss\n",
    "\n",
    "# QUESTION: Is there a better margin? or wrose?\n",
    "criterion = cuda(MarginRankingLoss(margin=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lib.pretrained_embeddings import FastText\n",
    "\n",
    "# Load embeddings\n",
    "if checkpoint is None:\n",
    "    unk_init = lambda t: torch.FloatTensor(t).uniform_(-0.1, 0.1)\n",
    "    pretrained_embedding = FastText(language='en', cache='./../../.pretrained_embeddings_cache')\n",
    "    text_embedding_weights = torch.Tensor(text_encoder.vocab_size, pretrained_embedding.dim)\n",
    "    for i, token in enumerate(text_encoder.vocab):\n",
    "        text_embedding_weights[i] = pretrained_embedding[token]\n",
    "    relation_word_embedding_weights = torch.Tensor(relation_word_encoder.vocab_size, pretrained_embedding.dim)\n",
    "    for i, token in enumerate(relation_word_encoder.vocab):\n",
    "        relation_word_embedding_weights[i] = pretrained_embedding[token]\n",
    "    entity_embedding_weights = torch.Tensor(entity_encoder.vocab_size, pretrained_embedding.dim)\n",
    "    for i, token in enumerate(entity_encoder.vocab):\n",
    "        entity_embedding_weights[i] = pretrained_embedding[token]\n",
    "    pretrained_embedding = None # Clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from lib.nn import YuModelEntity\n",
    "\n",
    "def make_model():\n",
    "    if checkpoint is None:\n",
    "        model = YuModelEntity(relation_encoder.vocab_size,\n",
    "                              relation_word_encoder.vocab_size, entity_encoder.vocab_size, \n",
    "                              text_encoder.vocab_size)\n",
    "        for param in model.parameters():\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "        model.text_embedding.weight.data.copy_(text_embedding_weights)\n",
    "        model.relation_word_embedding.weight.data.copy_(relation_word_embedding_weights)\n",
    "        model.entity_embedding.weight.data.copy_(entity_embedding_weights)\n",
    "        \n",
    "        freeze_embeddings = True\n",
    "        model.text_embedding.weight.requires_grad = not freeze_embeddings\n",
    "        model.relation_word_embedding.weight.requires_grad = not freeze_embeddings\n",
    "        model.entity_embedding.weight.requires_grad = not freeze_embeddings\n",
    "        \n",
    "        cuda(model)\n",
    "        return model\n",
    "    else:\n",
    "        model = checkpoint.model\n",
    "        model = copy.deepcopy(model)\n",
    "        cuda(model)\n",
    "        model.relation_word_rnn.flatten_parameters()\n",
    "        model.text_rnn_layer_one.flatten_parameters()\n",
    "        model.text_rnn_layer_two.flatten_parameters()\n",
    "        model.relation_rnn.flatten_parameters()\n",
    "        model.entity_rnn.flatten_parameters()\n",
    "        return model\n",
    "\n",
    "# Test that making the model works\n",
    "model_test = make_model()\n",
    "model_test = None # Clear memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Optimizer \n",
    "\n",
    "Instantiate the gradient descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "from lib.optim import Optimizer\n",
    "\n",
    "# https://github.com/pytorch/pytorch/issues/679\n",
    "def make_optimizer(model):\n",
    "    params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = Optimizer(SGD(params=params, lr=1))\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Below here, we do a training loop over a number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Directory: logs/0000.01-22_16:01:47.yu_relation_model\n",
      "Devevelopment Batch Size: 2048\n",
      "Train Batch Size: 128\n",
      "Epochs: 30\n",
      "Total Parameters: 5756400\n",
      "Model:\n",
      "YuModelEntity(\n",
      "  (relation_embedding): Embedding(5268, 300, padding_idx=0)\n",
      "  (relation_word_embedding): Embedding(3390, 300, padding_idx=0)\n",
      "  (relation_word_rnn): LSTM(300, 200, bidirectional=True)\n",
      "  (relation_rnn): LSTM(300, 200, bidirectional=True)\n",
      "  (entity_embedding): Embedding(48079, 300, padding_idx=0)\n",
      "  (entity_rnn): LSTM(300, 200, bidirectional=True)\n",
      "  (text_embedding): Embedding(6428, 300, padding_idx=0)\n",
      "  (text_rnn_layer_one): LSTM(300, 200, bidirectional=True)\n",
      "  (text_rnn_layer_two): LSTM(400, 200, bidirectional=True)\n",
      "  (distance): CosineSimilarity(\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from lib.utils import get_total_parameters\n",
    "from lib.utils import get_log_directory_path\n",
    "\n",
    "epochs = 30\n",
    "patience = 3\n",
    "train_batch_size = 128\n",
    "train_max_batch_size = 2048\n",
    "dev_batch_size = 4096\n",
    "log_directory = get_log_directory_path('yu_relation_model')\n",
    "model = make_model()\n",
    "optimizer = make_optimizer(model)\n",
    "\n",
    "print('Log Directory: %s' % log_directory)\n",
    "print('Devevelopment Batch Size: %s' % dev_batch_size)\n",
    "print('Train Batch Size: %s' % train_batch_size)\n",
    "print('Epochs: %s' % epochs)\n",
    "print('Total Parameters: %d' % get_total_parameters(model))\n",
    "print('Model:\\n%s' % model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d064ed91a5454ca1aa666230bb0730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved Checkpoint: logs/0000.01-22_16:01:47.yu_relation_model/01m_22d_16h_06m_29s.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae234fa2b2b6411f88ea7ddef699b605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=96), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.844188 [9151 of 10840]\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e5aa2790b745fa9df1ac9d1b263ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved Checkpoint: logs/0000.01-22_16:01:47.yu_relation_model/01m_22d_16h_12m_01s.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b206af1b9beb4b0da2fd43dc64167043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=96), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.862731 [9352 of 10840]\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209bb907f1c04d0a9b8d61a132b18be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved Checkpoint: logs/0000.01-22_16:01:47.yu_relation_model/01m_22d_16h_17m_24s.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334fdceed4034245936c1a653a38a148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=96), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.865221 [9379 of 10840]\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82c101fcbe84a6a86e1408126ec600c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved Checkpoint: logs/0000.01-22_16:01:47.yu_relation_model/01m_22d_16h_22m_44s.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0a3c05dfba4500a4011bd2a0c4b1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=96), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.868911 [9419 of 10840]\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668956fbba2e4066b6357861a1a4b8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict\n",
    "\n",
    "from lib.checkpoint import Checkpoint\n",
    "\n",
    "n_bad_epochs = 0\n",
    "last_accuracy = 0\n",
    "\n",
    "# Train!\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch %d' % epoch)\n",
    "\n",
    "    # Iterate over the training data\n",
    "    model.train(mode=True)\n",
    "    train_iterator = make_train_iterator(train_batch_size)\n",
    "    for (question, entity, true_relation, true_relation_word, false_relation,\n",
    "         false_relation_word) in tqdm_notebook(train_iterator):\n",
    "        optimizer.zero_grad()\n",
    "        output_true = model(\n",
    "            cuda_async(question), cuda_async(entity), cuda_async(true_relation), cuda_async(true_relation_word))\n",
    "        output_false = model(\n",
    "            cuda_async(question), cuda_async(entity), cuda_async(false_relation), cuda_async(false_relation_word))\n",
    "        labels = cuda(Variable(torch.ones(output_true.size()[0])))\n",
    "        loss = criterion(output_true, output_false, labels)\n",
    "\n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save checkpoint\n",
    "    print('Saved Checkpoint:', Checkpoint.save(\n",
    "        log_directory, {\n",
    "            'model': model,\n",
    "            'relation_word_encoder': relation_word_encoder,\n",
    "            'relation_encoder': relation_encoder,\n",
    "            'text_encoder': text_encoder\n",
    "        },\n",
    "        device=device))\n",
    "\n",
    "    # Evaluate\n",
    "    model.train(mode=False)\n",
    "    examples = defaultdict(list)\n",
    "    dev_iterator = make_dev_iterator(dev_batch_size)\n",
    "    for (question, entity, relation, relation_word, batch) in tqdm_notebook(dev_iterator):\n",
    "        output = model(cuda_async(question), cuda_async(entity), cuda_async(relation), cuda_async(relation_word))\n",
    "        output = output.data.cpu()\n",
    "\n",
    "        for i, row in enumerate(batch):\n",
    "            examples[row['Example ID']].append({\n",
    "                'Score': output[i],\n",
    "                'Question': row['Question'],\n",
    "                'True Relation': row['True Relation'],\n",
    "                'Relation': row['Relation']\n",
    "            })\n",
    "\n",
    "    # Print metrics\n",
    "    correct = 0\n",
    "    for pool in examples.values():\n",
    "        max_relation = max(pool, key=lambda p: p['Score'])\n",
    "        if max_relation['Relation'].tolist() == max_relation['True Relation'].tolist():\n",
    "            correct += 1\n",
    "    accuracy = correct / len(examples)\n",
    "    print('Accuracy: %f [%d of %d]' % (accuracy, correct, len(examples)))\n",
    "    print()\n",
    "    \n",
    "    # Scheduler for increasing batch_size inspired by this paper:\n",
    "    # https://openreview.net/forum?id=B1Yy1BxCZ\n",
    "    if last_accuracy > accuracy:\n",
    "        n_bad_epochs += 1\n",
    "    elif accuracy > last_accuracy:\n",
    "        n_bad_epochs = 0\n",
    "        \n",
    "    if n_bad_epochs > patience:\n",
    "        train_batch_size = min(train_max_batch_size, train_batch_size * 2)\n",
    "        print('Ran out of patience, increasing train batch size to:', train_batch_size)\n",
    "        n_bad_epochs = 0\n",
    "        \n",
    "    last_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Play around with the evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from lib.checkpoint import Checkpoint\n",
    "\n",
    "model = make_model()\n",
    "model.train(mode=False)\n",
    "examples = defaultdict(list)\n",
    "dev_iterator = make_dev_iterator()\n",
    "for (question, relation, relation_word, batch) in tqdm_notebook(dev_iterator):\n",
    "    output = model(cuda_async(question), cuda_async(relation), cuda_async(relation_word))\n",
    "    output = output.data.cpu()\n",
    "\n",
    "    for i, row in enumerate(batch):\n",
    "        examples[row['Example ID']].append({\n",
    "            'Score': output[i],\n",
    "            'Question': text_encoder.decode(row['Question']),\n",
    "            'True Relation': relation_encoder.decode(row['True Relation']),\n",
    "            'Relation': relation_encoder.decode(row['Relation'])\n",
    "        })\n",
    "\n",
    "# Print metrics\n",
    "correct = 0\n",
    "for id_, pool in sorted(examples.items(), key=lambda item: item[0]):\n",
    "    max_relation = max(pool, key=lambda p: p['Score'])\n",
    "    if max_relation['Relation'] == max_relation['True Relation']:\n",
    "        correct += 1\n",
    "print('Accuracy: %f [%d of %d]' % (correct / len(examples), correct, len(examples)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate similar to step 3 of our end-to-end implementation. This shows that the order of execution matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from lib.utils import pad_batch\n",
    "\n",
    "model = make_model()\n",
    "cuda = lambda v: v.cuda() if torch.cuda.is_available() else t\n",
    "to_variable = lambda b: cuda(Variable(torch.stack(b).t_().contiguous(), volatile=True))\n",
    "    \n",
    "def get_relation_scores(questions, relations):\n",
    "    questions = [q for q in questions]\n",
    "    questions_encoded, _ = pad_batch([text_encoder.encode(q) for q in questions])\n",
    "    relations_encoded, _ = pad_batch([relation_encoder.encode(r) for r in relations])\n",
    "    relations_word_encoded, _ = pad_batch([relation_word_encoder.encode(r) for r in relations])\n",
    "\n",
    "    questions_encoded = to_variable(questions_encoded)\n",
    "    relations_encoded = to_variable(relations_encoded)\n",
    "    relations_word_encoded = to_variable(relations_word_encoded)\n",
    "\n",
    "    return model(questions_encoded, relations_encoded, relations_word_encoded).data\n",
    "\n",
    "# To test this cell\n",
    "question = 'where was <e> born ?'\n",
    "print('Question:', question)\n",
    "# print('Scores:')\n",
    "print(get_relation_scores([question], ['people/person/place_of_birth']))\n",
    "print(get_relation_scores([question], ['location/location/people_born_here']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "\n",
    "relation_correct = 0\n",
    "df = pd.read_table('../../data/relation_ranking/dev.txt', \n",
    "                     header=None, names=['True Relation', 'Relation Pool', 'Question'])\n",
    "for i, row in tqdm_notebook(df.iterrows(), total=df.shape[0]):\n",
    "    candidate_relations = set(row['Relation Pool'].split())\n",
    "    true_relation = row['True Relation']\n",
    "    question = row['Question'].strip()\n",
    "    questions, relations = zip(*[(question, r) for r in candidate_relations])\n",
    "    scores = get_relation_scores(questions, relations)\n",
    "    max_relation = max([(r, i) for i, r in enumerate(candidate_relations)],\n",
    "                       key=lambda item: float(scores[item[1]]))[0]\n",
    "    \n",
    "    if max_relation == true_relation:\n",
    "        relation_correct += 1\n",
    "\n",
    "print('Relation Accuracy (SOTA 89%%): %f [%d of %d]' %\n",
    "          (relation_correct / df.shape[0], relation_correct, df.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
