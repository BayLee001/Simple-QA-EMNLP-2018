{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity ElasticSearch Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build up an ElasticSearch cluster for linking to the FB5M knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB5M = '../../data/simple_qa/freebase-FB5M.txt'\n",
    "\n",
    "# DOWNLOADED FROM: https://www.dropbox.com/s/yqbesl07hsw297w/FB5M.name.txt\n",
    "MID_TO_NAME = '../../data/simple_qa/FB5M.name.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12010500/12010500 [01:09<00:00, 173896.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Objects: 1972702\n",
      "Sample: [ ( '01hmz0g',\n",
      "    [ { 'property': 'music/album/genre',\n",
      "        'subjects': ['07sbbz2', '06by7', '02yv6b', '0155w', '0xhtw']},\n",
      "      {'property': 'music/album/album_content_type', 'subjects': ['0l14g2']},\n",
      "      {'property': 'music/album/release_type', 'subjects': ['02lx2r']},\n",
      "      {'property': 'music/album/artist', 'subjects': ['07mvp']}]),\n",
      "  ( '04y82y6',\n",
      "    [ { 'property': 'people/deceased_person/place_of_death',\n",
      "        'subjects': ['01pr6n']},\n",
      "      {'property': 'people/person/gender', 'subjects': ['05zppz']},\n",
      "      {'property': 'soccer/football_player/position_s', 'subjects': ['0dgrmp']},\n",
      "      {'property': 'people/person/nationality', 'subjects': ['02jx1']}]),\n",
      "  ( '0gys2jp',\n",
      "    [ { 'property': 'film/film/language',\n",
      "        'subjects': ['03115z', '03_9r', '02h40lc', '02k30q']},\n",
      "      { 'property': 'film/film/genre',\n",
      "        'subjects': ['07s9rl0', '082gq', '03hn0']},\n",
      "      {'property': 'film/film/directed_by', 'subjects': ['014hdb']},\n",
      "      {'property': 'film/film/country', 'subjects': ['0d05w3', '03h64']}]),\n",
      "  ( '0qfbk20',\n",
      "    [ {'property': 'people/person/profession', 'subjects': ['09l65']},\n",
      "      {'property': 'people/person/profession', 'subjects': ['09l65']},\n",
      "      {'property': 'people/person/profession', 'subjects': ['09l65']},\n",
      "      {'property': 'people/person/place_of_birth', 'subjects': ['018jcq']},\n",
      "      {'property': 'people/person/nationality', 'subjects': ['03_3d']},\n",
      "      {'property': 'common/topic/notable_types', 'subjects': ['0kpv1_']},\n",
      "      {'property': 'people/person/gender', 'subjects': ['02zsn']}]),\n",
      "  ( '0bst7',\n",
      "    [ { 'property': 'base/piercings/piercing/piercing_location',\n",
      "        'subjects': ['06pj2k']},\n",
      "      { 'property': 'base/piercings/piercing/piercing_location',\n",
      "        'subjects': ['06pj2k']},\n",
      "      { 'property': 'base/piercings/piercing/jewelry',\n",
      "        'subjects': ['01nv0m', '053t76']},\n",
      "      { 'property': 'base/piercings/piercing/jewelry',\n",
      "        'subjects': ['01nv0m', '053t76']},\n",
      "      { 'property': 'common/topic/image',\n",
      "        'subjects': ['03svbck', '02bm0vt', '042lrcp']},\n",
      "      { 'property': 'common/topic/image',\n",
      "        'subjects': ['03svbck', '02bm0vt', '042lrcp']}])]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "object_to_fact = defaultdict(list)\n",
    "for i, line in tqdm(enumerate(open(FB5M, 'r')), total=12010500):\n",
    "    split = line.split('\\t')\n",
    "    assert len(split) == 3, 'Malformed row'\n",
    "    object_ = split[0].replace('www.freebase.com/m/', '').strip()\n",
    "    property_ = split[1].replace('www.freebase.com/', '').strip()\n",
    "    subjects = [url.replace('www.freebase.com/m/', '').strip() for url in split[2].split()]\n",
    "    object_to_fact[object_].append({'property': property_, 'subjects': subjects })\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "print()\n",
    "print('Number of Objects:', len(object_to_fact))\n",
    "print('Sample:', pp.pformat(random.sample(object_to_fact.items(), 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1954466 mappings\n"
     ]
    }
   ],
   "source": [
    "mid_to_name = {}\n",
    "for i, line in enumerate(open(MID_TO_NAME)):\n",
    "    split = line.strip().split('\\t')\n",
    "    print(split)\n",
    "    break\n",
    "print('Got %d mappings' % len(mid_to_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health: %s {'active_primary_shards': 15, 'number_of_nodes': 1, 'number_of_in_flight_fetch': 0, 'number_of_data_nodes': 1, 'relocating_shards': 0, 'initializing_shards': 0, 'cluster_name': 'elasticsearch_petrochuk', 'active_shards': 15, 'timed_out': False, 'number_of_pending_tasks': 0, 'delayed_unassigned_shards': 0, 'unassigned_shards': 15, 'task_max_waiting_in_queue_millis': 0, 'status': 'yellow', 'active_shards_percent_as_number': 50.0}\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl.connections import connections\n",
    "\n",
    "# Define a default Elasticsearch client\n",
    "connections.create_connection(hosts=['localhost'])\n",
    "\n",
    "# Display cluster health\n",
    "print('Health: %s', connections.get_connection().cluster.health())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1113000 documents in index \"fb5m_entities\"\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "\n",
    "client = Elasticsearch()\n",
    "ENTITY_INDEX = 'fb5m_entities'\n",
    "\n",
    "# check if last entity exists, then do not refetch\n",
    "num_entities = 0\n",
    "if client.indices.exists(index=ENTITY_INDEX):\n",
    "    search = Search(using=client, index=ENTITY_INDEX)\n",
    "    query = search.query(\"match_all\")\n",
    "    num_entities = query.count()\n",
    "    print('Found %d documents in index \"%s\"' % (query.count(), ENTITY_INDEX))\n",
    "else:\n",
    "    print('%s index does not exist' % ENTITY_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import DocType\n",
    "from elasticsearch_dsl import Index\n",
    "from elasticsearch_dsl import Integer\n",
    "from elasticsearch_dsl import Nested\n",
    "from elasticsearch_dsl import Search\n",
    "from elasticsearch_dsl import String\n",
    "\n",
    "class FreebaseEntity(DocType):\n",
    "    mid = String(index='not_analyzed')\n",
    "    name = String()\n",
    "    facts = Nested(required=True,\n",
    "                   properties={'subjects': String(index='not_analyzed'),\n",
    "                               'property': String(index='not_analyzed')})\n",
    "\n",
    "    class Meta:\n",
    "        index = ENTITY_INDEX\n",
    "\n",
    "    def save(self, **kwargs):\n",
    "        return super().save(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - Delete 1113000 entities? [YES/no] YES\n",
      "1086000 - Done"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "from elasticsearch.helpers import streaming_bulk\n",
    "\n",
    "# save entities to elastic search\n",
    "def get_entities():\n",
    "    for mid in all_mids:\n",
    "        if mid in mid_to_name and mid in object_to_fact:\n",
    "            yield {\n",
    "                'mid': mid,\n",
    "                'name': mid_to_name[mid],\n",
    "                'facts': object_to_fact[mid]\n",
    "            }\n",
    "    \n",
    "\n",
    "def serialize_entity(mid, name, facts):\n",
    "    \"\"\" serialize the instance into a dictionary so that it can be saved in elasticsearch. \"\"\"\n",
    "    return FreebaseEntity(\n",
    "        mid=mid,\n",
    "        facts=facts,\n",
    "        name=name,\n",
    "        meta={'id': mid}).to_dict(True)\n",
    "\n",
    "\n",
    "def save_entities():\n",
    "    \"\"\" efficiently save entities in bulk using `streaming_bulk` and `serialize_entity` \"\"\"\n",
    "    elasticsearch_connection = connections.get_connection()\n",
    "    task_generator = (serialize_entity(**kwargs) for kwargs in get_entities())\n",
    "    for i, (ok, item) in enumerate(streaming_bulk(elasticsearch_connection, task_generator,\n",
    "                                                  chunk_size=100, request_timeout=120)):\n",
    "        if i % 100 == 0:\n",
    "            sys.stdout.write(\"\\r%d - Done\" % (i))\n",
    "            sys.stdout.flush()\n",
    "        if not ok:\n",
    "            print(item)\n",
    "    print()        \n",
    "\n",
    "\n",
    "# save entities if not already saved\n",
    "def create_index():\n",
    "    input_ = input('WARNING - Delete %d entities? [YES/no] ' % num_entities)\n",
    "    if input_ == 'YES':\n",
    "        client.indices.delete(index=ENTITY_INDEX)\n",
    "        # create the mappings in elasticsearch\n",
    "        FreebaseEntity.init()\n",
    "        save_entities()\n",
    "    else:\n",
    "        print('Not Deleting Index! Wohoo!')\n",
    "    print('Done!')\n",
    "\n",
    "\n",
    "create_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
