{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/people/person/gender', '/music/release/track', '/soccer/football_player/position_s', '/organization/organization_founder/organizations_founded', '/cvg/computer_videogame/cvg_genre']\n"
     ]
    }
   ],
   "source": [
    "lookup = [line.strip() for line in open('../../data/relation_lookup.tsv', 'r')]\n",
    "print(lookup[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['40', '61 40 117', 'which genre of album is #head_entity# ?'], ['61', '56 702 132 61 117 40 11', 'what format is #head_entity#'], ['272', '7 1 18 272 308', 'what film is by the writer #head_entity# ?'], ['37', '11 135 1 6 37 18', 'where did #head_entity# die'], ['125', '1 37 18 353 125 162 11 7 1611 414 6 373 537 500', 'what was the cause of death of #head_entity#']]\n",
      "20609\n"
     ]
    }
   ],
   "source": [
    "results = [line.strip().split('\\t') for line in open('../../data/relation_res.tsv', 'r')]\n",
    "print(results[:5])\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/music/album/genre', 'which genre of album is'), ('/music/album/release_type', 'what format is'), ('/film/writer/film', 'what film is by the writer'), ('/people/deceased_person/place_of_death', 'where did'), ('/people/deceased_person/cause_of_death', 'what was the cause of death of')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/music/album/genre', 'which genre of album is harder.....faster?'), ('/music/album/release_type', 'what format is fearless'), ('/people/person/place_of_birth', 'what city was alex golfis born in'), ('/film/writer/film', 'what film is by the writer phil hay?'), ('/people/deceased_person/place_of_death', 'where did roger marquis die')]\n",
      "21687\n"
     ]
    }
   ],
   "source": [
    "data = [line.strip().split('\\t') for line in open('../../data/SimpleQuestions_v2/annotated_fb_data_test.txt', 'r')]\n",
    "true = [(row[1].replace('www.freebase.com', ''), row[3].lower()) for row in data]\n",
    "print(true[:5])\n",
    "print(len(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/music/album/genre', 'which genre of album is'), ('/music/album/release_type', 'what format is'), ('/film/writer/film', 'what film is by the writer'), ('/people/deceased_person/place_of_death', 'where did'), ('/people/deceased_person/cause_of_death', 'what was the cause of death of')]\n",
      "0.9288513856227233\n",
      "correct 20144\n",
      "incorrect 465\n",
      "0\n",
      "21687\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from Levenshtein import distance\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "predictions = [(lookup[int(result[0]) - 1], result[2].split('#')[0].strip()) for result in results]\n",
    "print(predictions[:5])\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "prediction_relation, prediction_question = predictions.pop(0)\n",
    "for true_relation, true_question in true:\n",
    "    diff = distance(prediction_question, true_question) - len(true_question) + len(prediction_question)\n",
    "    if diff < 6:\n",
    "        if true_relation == prediction_relation:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "        if len(predictions) == 0:\n",
    "            break;\n",
    "        prediction_relation, prediction_question = predictions.pop(0)\n",
    "print('accuracy', correct / len(true))\n",
    "print('correct', correct)\n",
    "print('incorrect', incorrect)\n",
    "print(len(predictions))\n",
    "print(len(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9502928021395306\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions) / len(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
